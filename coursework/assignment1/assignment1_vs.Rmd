---
title: "Assignment 1"
author: "Victoria Shi"
date: "10/09/2024"
output:
  pdf_document:
  html_document:
    toc: true
    theme: flatly
    highlight: tango
    df_print: paged
toc: true
editor_options:
chunk_output_type: inline
---

```{r setup, warning = FALSE, include=FALSE,echo=FALSE,message=FALSE}
library(tidyr)
library(dplyr)

library(RColorBrewer)
library(tidyverse)
library(tidyquant)
library(broom)
library(umap)
library(plotly)
library(dplyr)
library(ggplot2)
library(cluster)
library(psych)
library(factoextra)
conflicted::conflict_prefer("select", "dplyr")
conflicted::conflict_prefer("filter", "dplyr")
library(quantmod)
gradient <- viridis::mako(8)
# start with lighter color
gradient <- gradient[8:3]
colors <- brewer.pal(8, "Pastel2")
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  tidy = TRUE
)
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.align = "center"
)
setwd("~/RProjects/data315-au24/coursework/assignment1")

# install.packages("plotly")
library(dplyr)
library(purrr)
library(xts)
library(TTR)
library(tidyr)
library(quantmod)
library(tidyverse)
library(tidyquant)
library(PerformanceAnalytics)
library(yfR)
library(dplyr)
library(dendextend)
library(RColorBrewer)
library(factoextra)
library(cluster)
library(lubridate)
library(stats)
library(janitor)
conflicted::conflicts_prefer(dplyr::filter)
conflicted::conflicts_prefer(dplyr::select)
library(gridExtra)
library(grid)
theme_set(theme_light())
library(RColorBrewer)
palette(brewer.pal(6, "Pastel2"))
# ignorne knitr warnings and eroors
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
conflicted::conflicts_prefer(dplyr::lag)
library(tidyverse)
library(tidyquant)
library(broom)
library(umap)
library(plotly)
library(dplyr)
# Set the theme and palette
library(ggplot2)
library(RColorBrewer)

theme_set(theme_light()) # Light theme
palette(brewer.pal(6, "Pastel2")) # Pastel color palette
library(rvest)  # web scraping
library(dplyr)
library(janitor)  # cleaning names
library(tidyquant)
library(purrr)
knitr::opts_chunk$set(
    echo = TRUE,
    message = FALSE,
    warning = FALSE,
    tidy = TRUE
    )
```

```{r,include=FALSE}
# Loading the necessary libraries
library(rvest)  # for web scraping
library(dplyr)  # for data manipulation
library(janitor)  # for cleaning names
library(tidyquant)  # for financial data extraction
library(purrr)  # for list manipulation
```
## Introduction

Companies often aim to target new products or technologies to potential customers across different market segments. Similarly, investors may want to seek out new investment opportunities or launch startups, where the newcomers might not have enough established history. Oftentimes, they have access to historical data. Stock prices can serve as a useful indicator to gauge a companyâ€™s trading patterns and overall performance. Analyzing stock returns in this context can help classify companies and potentially identify competitors or those with similar attributes. Stakeholders can use these insights to refine their strategies in targeting business in certain sectors.


In this scenario, stock prices are two fair indicators of a company's trading patterns and performance. Thus, we might classify companies based on their stock returns and, by analyzing the cluster properties, derive further insights. These could potentially help the stakeholders identify competitors and companies with similar attributes.

### Objective
We will use various visualization techniques to explore the data, identify key patterns, and investigate relationships between variables.


The objective of this analysis is to:
- Perform exploratory data analysis on S&P 500 stock data.
- Use clustering methods to group companies based on stock return behaviors.
- Interpret these clusters to uncover meaningful insights into sector performance and company behaviors.


# 1. Data Preparation

For this analysis, we gathered data from two sources:
- **S&P 500 company listings** from Wikipedia, which provides information on current and historical company data.
- **Stock price history** from Yahoo Finance, giving us daily price data, including open, high, low, and adjusted close prices.

Data is available and publiclaly,..
Data cleaning was necessary to ensure the datasets were consistent and ready for analysis. This included:
- Removing missing values, which could distort any analysis of stock performance.
- Converting date columns into a consistent format for time-series analysis.
- Filtering out irrelevant columns to focus on the most important variables, such as sector, adjusted close price, and volume.



```{r}
# scrape S&P 500 company data from Wikipedia

# URL of the Wikipedia page
url <- 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'

# Scraping the S&P 500 company data from the webpage
sp500 <- url %>% read_html() %>% html_table(fill = TRUE, trim = TRUE)

# Processing the current S&P 500 companies
current <- sp500[[1]] %>%
  janitor::clean_names() %>%
  as.data.frame() %>%
  mutate(founded = as.numeric(founded), `date_added` = as.Date(`date_added`)) %>%
  na.omit()

# Processing the historical changes
history <- sp500[[2]] %>%
  janitor::clean_names() %>%
  as.data.frame() %>%
  mutate(date = as.Date(date, format = "%B %d, %Y")) %>%
  rename('added_symbol' = added, 'added_security' = added_2, 'removed_symbol' = removed, 'removed_security' = removed_2) %>%
  na.omit()

```

Next, we extract the price history for the current S&P 500 companies from Yahoo Finance using the tidyquant() function in R, followed by further  cleansing, structuring, and transformations for analysis

```{r, eval=FALSE}
# Function to fetch stock price history for each company
pull_all_data <- . %>% tq_get(from = "2023-01-01") %>% as.data.frame()


# Retrieving stock price history for each S&P 500 company
sp500_price_data <- current %>%
  mutate(symbol = stringr::str_replace_all(string = symbol, pattern = '[.]', replacement = '-')) %>%
  mutate(data = map(symbol, pull_all_data)) %>%
  na.omit()

price_data <- sp500_price_data %>%
  mutate(data = map(data, ~mutate(.x, date = as.Date(date)))) %>% # convert date to date format
  select(-symbol) %>%
  unnest_legacy()
```

### Three Primary Datasets 
In summary, the data for this initial analysis consists of three primary tables: **historical changes in S&P 500 companies**, **current company data**, and **daily stock prices**.

##### 1. Historical Changes in S&P 500 Companies

'history' contains information on **historical changes** of the S&P 500 companies. It contains 353 rows, each documenting the addition or removal of companies in the S&P 500 index. Key columns include **date**, **added_security**, and **removed_security**, which track the timeline and specifics of index changes. Each row represents a record on the same day, where a company can be added, another can be removed, or both, 


```{r}
glimpse(history)
```


##### 2. **Current S&P 500 Companies**: 

Table 'current' contains detailed information on 461 companies, including **sector**, **sub-industry**, and **headquarters location**. These features provide essential context for sector-based analysis and performance evaluation.

```{r}
glimpse(current)
```



##### 3. **Daily Stock Prices**

The 'stock price data' contains over 200,000 rows of stock price data, including its high, low, open, close, which are crucial for calculating returns. Key variables, such as **adjusted close prices**, are essential for calculating returns, while **volume** and **date** will aid in understanding market activity over time.



```{r, include=FALSE}
#write_csv(sp500_price_data,"data/sp500_price_data.csv")
#saveRDS(price_data,"data/price_data.RData")
price_data <- readRDS("data/sp500_price_data.RData") %>%
  mutate(data = map(data, ~mutate(.x, date = as.Date(date)))) %>% # convert date to date format
  select(-symbol) %>%
  unnest_legacy()
```



```{r}
glimpse(price_data)
```
In sum, we have a variety of information on both the companies and their stock. Features like sector, subsector, and headquarters_location  might serve as useful indicators if we want to cluster companies, for example. They might also potentially be used as predictors of a regression model, which we might want to look into later.   

### Derived Data 

While we have plenty of information regarding the different prices of a particular stock, not all are equally useful - some may be highly correlated or redundant, or some are just less informative. When people were talking about investment or reward returns from investment, the primary metric uses percentage return: the percentage change in adjusted close price from period $i-1$ to period $i$:

\[
R_i=\frac{P_i-P_{i-1}}{P_{i-1}}=\frac{P_i}{P_{i-1}}-1, \quad t=1,2, \ldots
\]

The period could be a day, a week, or a month. The percentage naturally normalizes the return and is useful especially when comparing different companies or sectors over time, instilling confidence in its use.

For this exploratory analysis, I chose the adjusted close price (adjusted) for the price $ P$ in the formula above. The adjusted close price neutralizes the effects of corporate actions that would otherwise alter the stock's price. In other words, it reflects the true value of a stock rather than its performance.

```{r}
# if not exist price_data, returns, or returns_wide, import them
if (!exists("price_data")) {
  price_data <- readRDS("data/sp500_price_data.RData")
}
```


```{r, eval=FALSE}
# Calculating the daily returns for each stock
returns_all <- price_data %>%
  arrange(symbol, date) %>%
  group_by(symbol) %>% # group by symbol to calculate returns for each company
  mutate(return = (adjusted - lag(adjusted)) / adjusted * 100) %>%
  na.omit() %>%
  ungroup()

# filter out only the most relevant columns
returns <- returns_all[,c(1,8:16)]
```

```{r, include=FALSE}
#saveRDS(returns_all, "/Users/victoriashi/RProjects/data315-au24/coursework/assignment1/data/returns_all.RData")
#saveRDS(returns, "data/returns.RData")
returns_all <- readRDS("data/returns_all.RData")
returns <- readRDS("data/returns.RData")
```


This is a more intuitive and concise representation of the previous return data.


```{r, eval=FALSE}
# a more intuitive format:  symbol-return on each date
returns_wide <- returns %>%
  #  symbol in 1st column, follow by the stock return on each day in all other columns of every stock
  pivot_wider(id_cols = date, names_from = symbol, values_from = return)

returns_new <- returns %>%
  #  symbol in 1st column, follow by the stock return on each day in all other columns of every stock
  pivot_wider(id_cols = symbol , names_from = date, values_from = return)

head(returns_wide)
```

# Exploratory Data Analysis


## Univariate Analysis

```{r}

if (!exists("returns")) {
  returns <- readRDS("data/returns.RData")
}
if (!exists("returns_wide")) {
  returns_wide <- readRDS("data/returns_wide.RData")
}

if (!exists("returns_all")) {
  returns_all <- readRDS("data/returns_all.RData")
}

```


### Market Composition via Sector Breakdown

To begin our analysis, we examine the distribution of companies across various sectors within the S&P 500 index. The sector breakdown provides a rough idea of the market composition,

We calculate the number of companies in each sector and the proportional representation of each sector.


```{r}
# Count the number of companies in each sector (gics_sector)
sectors <- price_data %>%
  group_by(gics_sector) %>%
  summarise(company_count = n()) %>%
  arrange(desc(company_count)) %>%
  mutate(percentage = round(100 * company_count / sum(company_count), 1))


sectors <- sectors %>% mutate(label = paste0(company_count, "\n(", percentage, "%)"))

# Company Distribution in the S&P 500
ggplot(sectors, aes(x = "", y = company_count, fill = gics_sector)) +
  geom_bar(stat = "identity", width = .5) +
  coord_polar("y", start = 0) +
  scale_fill_brewer(palette = "Set3") +
  labs(title = "S&P 500 Sector Breakdown") +
  theme_void() +
  geom_text(angle = 10, aes(label = sectors$label), position = position_stack(vjust = 0.5), size = 3)
```


The pie chart more or less reflects the diversified nature of the S&P 500, but the concentration in these sectors points to where much of the marketâ€™s value is generated is also very pronounced. 

The Information Technology, Financials, Industrials, and Health Care sectors dominate the S&P 500, together accounting for a significant portion of the companies in the index. Each of these sectors represents over 10% of the total companies, showcasing their substantial influence on the market.

The remaining sectors each make up less than 10% of the total companies. Communication Services and Energy sectors are the least represented. This underrepresentation could be due to economic shifts toward Information Technology and the fact that many entities within Energy and Communication Services are government-owned or public utilities, which are not as heavily represented in the publicly traded market. These trends reflect broader structural changes in the economy.


If we focus on the top four sectorsâ€”Information Technology, Financials, Industrials, and Health Careâ€”it seems these sectors divide the market relatively evenly. 

```{r}
sectors %>%
  slice(1:4) %>%
  ggplot(., aes(x = "", y = company_count, fill = gics_sector)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  scale_fill_brewer(palette = "Set3") +
  labs(title = "Top 5 Sectors in Current S&P 500") +
  theme_void() +
  geom_text(angle = 45, aes(label = company_count), position = position_stack(vjust = 0.5), size = 3, check_overlap = TRUE)

```





### Price Metrics

We explored the key stock by visualizing various different price metrics (adjusted, high, and low prices) for various sectors of the S&P 500 over time. 

```{r}
price_long <- price_data %>%
  group_by(gics_sector) %>%
  pivot_longer(cols = c("high","low","adjusted"), names_to = "price_type", values_to = "price_value")

# different price metrics (adjusted, high, and low prices) for different companies
price_long %>%
  ggplot(aes(x = date, y = price_value, color = price_type)) +
  geom_point(size = 0.1) +
  facet_wrap(~gics_sector, scales = "free_y") +
  scale_color_brewer(palette = "Pastel2") +
  labs(title = "Price Metrics Comparison by Sector", x = "Date", y = "Price Value") +
  theme_minimal(base_size = 8) +
  theme(legend.position = "top")


```


The visualization offers a detailed view of price metrics (high, low, and adjusted) across different sectors over time. However, while it provides an informative comparison of price movement patterns within each sector over time, it might not be really useful.

### Volume Distribution by GICS Sector:

This plot shows the **trading volume density distribution** across different GICS sectors in the S&P 500. Trading volume provides insights into the **market liquidity** and **investor interest** in different sectors.

```{r}
#  volume data across sectors over time
volume_data <- price_data %>%
  group_by(gics_sector) %>%
  pivot_longer(cols = "volume", names_to = "volume_type", values_to = "volume") %>%
  # by sector; only compare the volume
  # take the mean vaolume for one sector on each day and plot
  group_by(date, gics_sector, volume_type) %>%
  summarise(mean_volume = mean(volume, na.rm = TRUE))



# distribution plot
volume_data %>% ggplot(aes(x = mean_volume, fill = gics_sector)) +
  geom_density(alpha = 0.5) +
  scale_fill_brewer( #discrete_scale
    palette = "Set3") +
  labs(title = "Volume Distribution by GICS Sector", x = "Volume", y = "Density") +
  theme_minimal() +
  theme(legend.position = "top")
```



- **Highly Traded Sectors**: **Financials**, **Health Care**, and **Information Technology** sectors exhibit significantly higher trading volumes, peaking sharply at lower volume values. This suggests that these sectors experience **high liquidity**, making them attractive for both short-term traders and institutional investors.
  
- **Low Volume Sectors**: Sectors such as **Real Estate**, **Energy**, and **Communication Services** have lower overall trading volumes, reflecting less active trading and possibly indicating **less market liquidity**. Companies in these sectors may attract long-term investors focused on fundamentals rather than frequent trading.
  
- **Sector Comparisons**: The **Information Technology** and **Health Care** sectors, though showing slightly lower density peaks than **Financials**, have a **broader distribution**, suggesting more variation in trading volumes within these sectors. This indicates that while some companies have high trading volumes, others may be less frequently traded, adding to the diversity within these sectors.

In summary, the **density peaks** highlight the sectors that dominate trading activity, while the tails of the distribution suggest sectors where investor activity is more sporadic or concentrated in fewer companies. These insights can help investors understand sector-specific dynamics when making market or trading decisions.


## Bivariate Analysis: Volume vs. Adjusted Price

Next, we explored the relationship between trading volume and adjusted close price. This bivariate analysis helps us understand whether higher trading volumes correspond to higher price fluctuations.
```{r}
# Scatter plot of volume vs adjusted close price by sector
ggplot(price_data, aes(x = volume, y = adjusted, color = gics_sector)) +
  geom_point(alpha = 0.6) +
  scale_x_log10() +  # Log scale for volume to handle large range
  scale_y_log10() +  # Log scale for price for better visualization
  labs(title = "Trading Volume vs Adjusted Close Price",
       x = "Trading Volume (log scale)",
       y = "Adjusted Close Price (log scale)") +
  theme_minimal() +
  theme(legend.position = "bottom")
```


```{r}
# Calculate correlation for each sector
correlations <- price_data %>%
  group_by(gics_sector) %>%
  summarise(correlation = cor(volume, adjusted, use = "complete.obs"))

# Display correlations
correlations

```


```{r}
volume_data <- price_data %>%
  group_by(gics_sector) %>%
  summarise(mean_volume = mean(volume, na.rm = TRUE))

# ggplot(volume_data, aes(x = mean_volume, fill = gics_sector)) +
#   geom_density(alpha = 0.5) +
#   scale_fill_brewer(palette = "Set3") +
#   labs(title = "Volume Distribution by Sector", x = "Volume", y = "Density") +
#   theme_minimal()

```



### Adjusted Close Price vs Return

Observing the average daily stock returns across different sectors of companies, we can see that 


- Top Performing Sectors include Information Technology, Communication Services.
- Sectors such as Financials and Real Estate fall in the middle range.
- Sectors like Consumer Staples and Health Care have negative average daily returns.


```{r}
# Average daily stock returns across different sectors
mean_return <- returns_all %>%
  group_by(gics_sector) %>%
  summarise(mean_return = mean(return, na.rm = TRUE)) %>%
  arrange(desc(mean_return))

mean_return %>%
  ggplot(aes(x = reorder(gics_sector, mean_return), y = mean_return, fill = gics_sector)) +
  geom_bar(stat = "identity", fill = gray(0.8)) +
  coord_flip() +
  labs(title = "Average Daily Returns by Sector", x = "Sector", y = "Mean Return (%)") +
  theme_minimal() +
  theme(legend.position = "none")
```


### Looking at Sector Breakdown and Average Returns by Sector Together

Information Technology consistently has the highest average daily return, which aligns with broader market trends. Tech stocks have outperformed other sectors due to ongoing digital transformation and innovation.

At the same time, Information Technology and Financials display the most fluctuation in returns, indicating that risk is more concentrated in growth sectors. This suggests a trade-off between risk and return, especially when using competitive benchmarking.

It's important to note that the largest sectors in the S&P 500 are Financials, Industrials, Information Technology, and Health Care. Information Technology is both the most profitable and the most dominant sector. However, having the largest representation in the index doesnâ€™t necessarily equate to profitability, as seen with Health Care. This sector, which leans towards more public service-oriented industries, tends to be less volatile, offering steady but lower returns.

Interestingly, Financials was expected to be more profitable or have a higher return. However, it may be underperformed due to economic inflation, recent trade issues, and other macroeconomic factors affecting the financial industry.

### Percentage Returns vs. Absolute Price Changes

The Left Panel shows the mean adjusted close price across all companies from 2023 to 2024.

```{r}

plot_list <- list()

# Loop to calculate the mean of 'adjusted' and 'return' across all companies over time
for (metric in c("adjusted", "return")) {

  # Create the mean calculation for the chosen metric
  p <- returns_all %>%
    # Pivot the data so each symbol's 'metric' becomes a column
    pivot_wider(id_cols = date, names_from = symbol, values_from = all_of(metric)) %>%
    # Calculate the row-wise mean for all companies, excluding the date column
    mutate(mean_all = rowMeans(select(., -date), na.rm = TRUE)) %>%
    as.data.frame() %>%
    ggplot(aes(x = date, y = mean_all)) +
    geom_line(color = "blue") +
    labs(
      x = "", y = paste("", metric)) +
    theme_light()

  plot_list[[metric]] <- p
}

# Combine the two plots using grid.arrange
grid.arrange(
  plot_list[["adjusted"]],
  plot_list[["return"]],
  ncol = 2,
  top = textGrob(
    "Average Daily Adjusted Close Price (left) and Return (right) Across All Companies (2023â€“2024)",
    gp = gpar(fontsize = 11, fontface = "bold")
  )
)
```

- Returns measure the relative change in stock prices from one period to the next.
- It displays a pronounced upward trend.While it seem somehow counter-intuitive at first, it is in fact the case in a growing economy or during periods of market expansion or high inflation. Furthermore, since the S&P 500 is composed of large, established companies, many of which have demonstrated long-term growth, the mean adjusted price naturally rises over time.

- While individual daily returns fluctuate considerably, their overall range tends to be constrained (usually between -3% and 3%, depending on market conditions).
- By contrast, adjusted stock prices reflect absolute changes, which can be substantial over time. As seen in the left panel of the chart, the adjusted price rises from approximately 165 to over 220 between 2023 and 2024â€”a significant increase.

######  Takeaways
- Both Price metrics and percentage returns are associated with the market but behave differently.
- Even though returns exhibit high volatility on a daily basis, the overall difference in cumulative percentage returns from the beginning to the end of the period is relatively stable when compared to absolute price changes.
- Stock prices tend to drift upwards or downwards more prominently in terms of the values.
- While the overall market grows, day-to-day price changes can be erratic. In other words, despite short-term fluctuations, the market's overall trajectory is positive.

- *In relation to the following analysis*, the percentage returns naturally normalize the data and seem more suitable for more meaningful comparisons across companies, regardless of their price levels. Thus, I did the clustering based on returns, hoping to identify companies with similar performance patterns.


# Multivariate Analysis: Clustering & Multidimension Reduction

### Grouping Companies by Returns


```{r}
returns_new <- returns %>%
  #  symbol in 1st column, follow by the stock return on each day in all other columns of every stock
  pivot_wider(id_cols = symbol , names_from = date, values_from = return, values_fill = 0)

# one - abs(correlation) to get dissimilarity
ret_matrix <- returns_new %>% select(-symbol) %>% na.omit()
#ret_matrix <- as.matrix(returns_wide[, -1]) %>% na.omit()
corr_matrix <- cor(as.matrix(returns_wide[, -1]), use = "complete.obs")
dissimilarity_matrix <- as.dist(1 - corr_matrix)


hc <- dissimilarity_matrix  %>% hclust() #hierarchical clustering
cluster <- cutree(hc, k = 5)
# plot dendrogram with cluster
hc %>%
  as.dendrogram() %>%
  color_branches(k = 10) %>%
  color_labels(k = 10) %>%
  set('labels_cex', 0.6) %>%
  plot(main = "Hiearchical Clustering")

```

```{r, include=FALSE}

# umap for 2D visualization

#umap_results <- umap::umap(ret_matrix, n_neighbors = 5, min_dist = 0.1, metric = "euclidean")
# visualize the results
# umap_results %>%
#   ggplot(aes(x = V1, y = V2)) +
#   geom_point() +
#   labs(title = "UMAP Visualization of Stock Returns", x = "UMAP 1", y = "UMAP 2") +
#   theme_minimal()
```



```{r}

# Perform PCA for visualization
pca_results <- prcomp(ret_matrix, scale. = TRUE)
pca_data <- as.data.frame(pca_results$x)
pca_data$cluster <- as.factor(k3$cluster)

# Plot PCA results with clusters
ggplot(pca_data, aes(x = PC1, y = PC2, color = cluster)) +
  geom_point(size = 2) +
  labs(title = "K-means Clustering (PCA Projection)", x = "PC1", y = "PC2") +
  theme_minimal()
```



```{r}
set.seed(0)
number_clusters <-3
#   k-means clustering with 5 centers
k3 <- kmeans(ret_matrix, centers = 3, nstart = 30)
k3$cluster %>% table()
fviz_cluster(k3, data = ret_matrix, ellipse.type = "convex", geom = "point", ellipse.level = 0.95, repel = TRUE, main = "Kmeans with 3 Clusters",
             ggtheme = theme_minimal())

```


```{r}
# 2.3 How many centers (customer groups) to use? ----

# Functions that works on 1 element
center <- 3

kmeans_mapper <- function(centers = 3) {
    
    returns_new %>% select(-symbol) %>% na.omit() %>%
        kmeans(centers = centers, nstart = 100)
}

3 %>% kmeans_mapper() %>% glance()
```


```{r}
# Mapping the function to many elements
kmeans_mapped_tbl <- tibble(centers = 1:20) %>%
    mutate(k_means = centers %>% map(kmeans_mapper)) %>%
    mutate(glance  = k_means %>% map(glance))

kmeans_mapped_tbl %>%
    unnest(glance) %>%
    select(centers, tot.withinss)
```


```{r}
# Skree Plot ----

kmeans_mapped_tbl %>%
    unnest(glance) %>%
    select(centers, tot.withinss) %>%
    
    # Visualization
    ggplot(aes(centers, tot.withinss)) +
    geom_point(color = "#2c3e50", size = 4) +
    geom_line(color = "#2c3e50", size = 1) +
    ggrepel::geom_label_repel(aes(label = centers), color = "#2c3e50") + 
    theme_tq() +
    labs(
        title = "Skree Plot"
    )
```
Conclusion: Based on the Scree Plot, we select 4 clusters to segment the customer base.



```{r}
# 2-D Projection ----

library(tidyverse)
library(broom)
library(umap)
library(ggrepel)
library(tidyquant)

umap_obj <- returns_new %>%
     select(-symbol)  %>%
    umap()
   

  
umap_results_tbl <- umap_obj$layout %>%
    as_tibble() %>%
    set_names(c("x", "y")) %>%
    bind_cols(
        returns_new %>% select(symbol)
    )

umap_results_tbl %>%
    ggplot(aes(x, y)) +
    geom_point() + 
    geom_label_repel(aes(label = symbol), size = 3)
```


```{r}
# 3.2 Use K-Means to Add Cluster Assignments ----
umap_results_tbl

kmeans_4_obj <- kmeans_mapped_tbl %>%
    pull(k_means) %>%
    pluck(4)

kmeans_4_clusters_tbl <- kmeans_4_obj %>% 
    augment(returns_new) %>%
    select(symbol, .cluster)

umap_kmeans_4_results_tbl <- umap_results_tbl %>%
    left_join(kmeans_4_clusters_tbl)
```


```{r}
# Projections with Cluster Assignments ----

umap_kmeans_4_results_tbl %>%
    mutate(label_text = str_glue("Customer: {symbol}
                                 Cluster: {.cluster}")) %>%
    
    ggplot(aes(x, y, color = .cluster)) +
    geom_point() +
    geom_label_repel(aes(label = label_text), size = 3) +
    
    # Formatting
    theme_tq() +
    scale_color_brewer(type = "qual") +
    labs(
        title = "Sector Segmentation by Stock Returns in the S&P 500 Index",
        subtitle = "2D projection"
    ) +
    theme(legend.position = "none") + 
    geom_label_repel(aes(label = symbol), size = 2)
```

     
```{r}
# 4.0 ANALYZE PURCHASING TRENDS ----

customer_trends_tbl %>%
    pull(price) %>%
    quantile(probs = c(0, 0.33, 0.66, 1))

?quantile

cluster_trends_tbl <- customer_trends_tbl %>%
    
    # Join Cluster Assignment by Bikeshop Name
    left_join(umap_kmeans_4_results_tbl) %>%
    
    mutate(price_bin = case_when(
        price <= 2240 ~ "low",
        price <= 4260 ~ "medium",
        TRUE ~ "high"
    )) %>% 
    
    select(.cluster, model, contains("price"), 
           category_1:quantity_purchased) %>%
    
    # Aggregate quantity purchased by cluster and product attributes
    group_by_at(.vars = vars(.cluster:frame_material)) %>%
    summarise(total_quantity = sum(quantity_purchased)) %>%
    ungroup() %>%
    
    # Calculate Proportion of Total
    group_by(.cluster) %>%
    mutate(prop_of_total = total_quantity / sum(total_quantity)) %>%
    ungroup()

cluster_trends_tbl
    

# Cluster 1 - Low/Medium Price, Road Model Preference
cluster_trends_tbl %>%
    filter(.cluster == 1) %>%
    arrange(desc(prop_of_total)) %>%
    mutate(cum_prop = cumsum(prop_of_total)) %>%
    View()

get_cluster_trends <- function(cluster = 1) {
    
    cluster_trends_tbl %>%
        filter(.cluster == cluster) %>%
        arrange(desc(prop_of_total)) %>%
        mutate(cum_prop = cumsum(prop_of_total)) 
    
}

get_cluster_trends(cluster = 1)

# Cluster 2 - Low/Medium Price, Mountain Model Preference, Aluminum Frame
get_cluster_trends(cluster = 2) %>% View()

# Cluster 3 - High End Price, Mountain Preference, Carbon Frame
get_cluster_trends(cluster = 3)

# Cluster 4 - High End Price, Road Preference, Carbon Frame
get_cluster_trends(cluster = 4)

```


## Possible Extensions



## Conclusion



