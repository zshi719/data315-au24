---
title: "Clustering with K-Means and UMAP: S&P 500 Stock Prices"
author: "Victoria Shi"
date: "2/19/2019"
output:
  html_document:
    toc: true
    theme: flatly
    highlight: tango
    df_print: paged
  pdf_document:
toc: true
editor_options:
  chunk_output_type: inline
---

```{r setup, warning = FALSE, include=FALSE,echo=FALSE,message=FALSE}
library(tidyr)
library(dplyr)

library(RColorBrewer)
library(tidyverse)
library(tidyquant)
library(broom)
library(umap)
library(plotly)
library(dplyr)
library(ggplot2)
library(cluster)
library(psych)
library(factoextra)
conflicted::conflict_prefer("select", "dplyr")
conflicted::conflict_prefer("filter", "dplyr")
library(quantmod)
gradient <- viridis::mako(8)
# start with lighter color
gradient <- gradient[8:3]
colors <- brewer.pal(8, "Pastel2")
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  tidy = TRUE
)
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.align = "center"
)
setwd("~/RProjects/data315-au24/coursework/assignment1")

# install.packages("plotly")
library(dplyr)
library(purrr)
library(xts)
library(TTR)
library(tidyr)
library(quantmod)
library(tidyverse)
library(tidyquant)
library(PerformanceAnalytics)
library(yfR)
library(dplyr)
library(dendextend)
library(RColorBrewer)
library(factoextra)
library(cluster)
library(lubridate)
library(stats)
library(janitor)
conflicted::conflicts_prefer(dplyr::filter)
conflicted::conflicts_prefer(dplyr::select)
library(gridExtra)
library(grid)
theme_set(theme_light())
library(RColorBrewer)
palette(brewer.pal(6, "Pastel2"))
# ignorne knitr warnings and eroors
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
conflicted::conflicts_prefer(dplyr::lag)
library(tidyverse)
library(tidyquant)
library(broom)
library(umap)
library(plotly)
library(dplyr)
# Set the theme and palette
library(ggplot2)
library(RColorBrewer)

theme_set(theme_light()) # Light theme
palette(brewer.pal(6, "Pastel2")) # Pastel color palette
library(rvest)  # web scraping
library(dplyr)
library(janitor)  # cleaning names
library(tidyquant)
library(purrr)

```


Set up:
For example, if we want to target a new product or technology to potential customers in different market segments, we have their purchase history, and now we want to identify similar companies.

In this scenario, stock prices are two fair indicators of a company's trading patterns and performance. Thus, we might classify companies based on their stock returns and, by analyzing the cluster properties, derive further insights. These could potentially help the stakeholders identify competitors and companies with similar attributes.


# 1. Data Preparation


# Data Scraping, Cleaning, & Wrangling


```{r,include=FALSE}
# Loading the necessary libraries

```


Scrape S&P 500 company data from Wikipedia

This chunk scrapes the S&P 500 data from Wikipedia amd extracts two tables: the first table containing relevant information of the Current S&P 500 companies, and the second table containing the historical changes, namely which companies were added or removed in the past.

```{r}
# scrape S&P 500 company data from Wikipedia

# url of the wikipedia page
url <- 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'

# read HTML page and extract tables.
sp500 <- url %>%
  read_html() %>%
  html_table(fill = TRUE, trim = TRUE)

# current S&P 500 companies
current <- sp500[[1]] %>%
  janitor::clean_names() %>%
  as.data.frame() %>%
  mutate(founded = as.numeric(founded), `date_added` = as.Date(`date_added`)) %>%
  na.omit()

# Historical Changes
history <- sp500[[2]] %>%
  .[-1,] %>%
  janitor::clean_names() %>%
  as.data.frame() %>%
  mutate(date = as.Date(date, format = "%B %d, %Y")) %>%
  rename(, 'added_symbol' = added, 'added_security' = added_2, 'removed_symbol' = removed, 'removed_security' = removed_2) %>%
  na.omit()
```


### Data Overview
The dataset includes '26' columns of key financial metrics for '45' publicly traded companies listed in the S&P 500 index. Each record provides financial data of one company.

```{r}
glimpse(current)
glimpse(history)
```

### Current and Historical S&P 500 Companies
Price history of the current S&P 500 companies

```{r, eval=FALSE}
# function to fetch the stock price history given the ticker
pull_all_data <- . %>%
  tq_get(from = "2023-01-01") %>%
  as.data.frame()


sp500_price_data <- current %>%
  # consistency - since sources use different formats
  mutate(symbol = stringr::str_replace_all(string = symbol, pattern = '[.]', replacement = '-')) %>%
  # loop through each symbol to retrieve its price history
  mutate(data = map(symbol, pull_all_data)) %>%
  na.omit()

#glimpse(sp500_price_data)
```


```{r}
# write_csv(sp500_price_data,"data/sp500_price_data.csv")
# saveRDS(sp500_price_data,"data/sp500_price_data.RData")
```


```{r}
price_data <- readRDS("data/sp500_price_data.RData") %>%
    mutate(data = map(data, ~mutate(.x, date = as.Date(date)))) %>% # convert date to date format
  select(-symbol) %>%
  unnest_legacy()

# head(price_data)
```
# 2. EDA



### Three Metrics: High, Low, and Adjusted Close Price
visualize all companies at once to decide which price metric (open, close, or adjusted) to focus on.
Box-plots for all companies across different metrics might compare the distributions.


```{r}
price_long <- price_data %>%
    group_by(gics_sector) %>%
  pivot_longer(cols = c("high","low","adjusted"), names_to = "price_type", values_to = "price_value")

price_long %>%
    ggplot(aes(x = date, y = price_value, color = price_type)) +
    geom_point(size = 0.1) +
    facet_wrap(~gics_sector, scales = "free_y") +
        # pastel
    scale_color_brewer(palette = "Pastel2") +
    labs(title = "Price Metrics Comparison by GICS Sector", x = "Date", y = "Price Value") +
    theme_minimal() +
    theme(legend.position = "top")


```



```{r}
#  volume data across sectors over time
volume_data <- price_data %>%
        group_by(gics_sector) %>%
    pivot_longer(cols = "volume", names_to = "volume_type", values_to = "volume") %>%
    # by sector; only compare the volume
    # take the mean vaolume for one sector on each day and plot
    group_by(date, gics_sector, volume_type) %>%
  summarise(mean_volume = mean(volume, na.rm = TRUE))


    # distribution plot
volume_data %>% ggplot(aes(x = mean_volume, fill = gics_sector)) +
    geom_density(alpha = 0.5) +
        scale_fill_brewer( #discrete_scale
        palette = "Set3") +
    labs(title = "Volume Distribution by GICS Sector", x = "Volume", y = "Density") +
    theme_minimal() +
    theme(legend.position = "top")


# then by date
volume_data %>%
        summarise(mean_volume = mean(volume, na.rm = TRUE)) %>%
        ggplot(aes(x = date, y = mean_volume, color = gics_sector)) +
        geom_line() +
        scale_fill_brewer(palette = "Set3") +
        labs(title = "Volume Distribution by GICS Sector", x = "Date", y = "Volume") +
        theme_minimal() +
        theme(legend.position = "top")


```

### Returns

The adjusted close price is used to calculate the returns because it  neutralizes the effects of corporate actions that would otherwise alter the stockâ€™s price and thus is meant to reflect the true value of a stock as opposed to its performance.  For example, if a company undergoes a 2-for-1 stock split, the price of the stock would be halved, but the adjusted price would be modified to reflect the pre-split value.

Since we are comparing across different companies or sectors over time across time periods, we might want to normalize the return. Thus, 'returns' are defined and calculated in this context as the percentage change in adjusted close price from period $i-1$ to period $i$:

\[
R_i=\frac{P_i-P_{i-1}}{P_{i-1}}=\frac{P_i}{P_{i-1}}-1, \quad t=1,2, \ldots
\]

The period could be a day, a week, or a month.

Compared to absolute price changes, percentage returns make it easier to compare both with itself, the relative change in value, and across companies.

```{r}
# if not exist price_data, returns, or returns_wide, import them
if (!exists("price_data")) {
  price_data <- readRDS("data/sp500_price_data.RData")
}
```

```{r, eval=FALSE}
# Calculating the daily returns for each stock
returns_all <- price_data %>%
  arrange(symbol, date) %>%
  group_by(symbol) %>% # group by symbol to calculate returns for each company
  mutate(return = (adjusted - lag(adjusted)) / adjusted * 100) %>%
  na.omit() %>%
  ungroup()


returns <- returns_all[,c(1,8:16)]
saveRDS(returns_all, "/Users/victoriashi/RProjects/data315-au24/coursework/assignment1/data/returns_all.RData")

saveRDS(returns, "data/returns.RData")
```


This is a more intuitive and concise representation of the previous return data.



```{r, eval=FALSE}
# a more intuitive format:  symbol-return on each date
returns_wide <- returns %>%
  #  symbol in 1st column, follow by the stock return on each day in all other columns of every stock
  pivot_wider(id_cols = date, names_from = symbol, values_from = return)
#head(returns_wide)

# saveRDS(returns_wide, "data/returns_wide.RData")
```




## Uni-variate Analysis

```{r}

if (!exists("returns")) {
  returns <- readRDS("data/returns.RData")
}
if (!exists("returns_wide")) {
  returns_wide <- readRDS("data/returns_wide.RData")
}

if (!exists("returns_all")) {
  price_data <- readRDS("data/returns_all.RData")
}

```
```{r}
# Count the number of companies in each sector (gics_sector)
sectors <- price_data %>%
  group_by(gics_sector) %>%
  summarise(company_count = n()) %>%
  arrange(desc(company_count)) %>%
  mutate(percentage = round(100 * company_count / sum(company_count), 1))


sectors <- sectors %>% mutate(label = paste0(company_count, "\n(", percentage, "%)"))

# Create the pie chart
ggplot(sectors, aes(x = "", y = company_count, fill = gics_sector)) +
  geom_bar(stat = "identity", width = .5) +
  coord_polar("y", start = 0) +
  scale_fill_brewer(palette = "Set3") +
  labs(title = "Sector Distribution in Current S&P 500 by Company Count") +
  theme_void() +
  geom_text(angle = 10, aes(label = sectors$label), position = position_stack(vjust = 0.5), size = 3)


sectors %>%
  slice(1:4) %>%
  ggplot(., aes(x = "", y = company_count, fill = gics_sector)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  scale_fill_brewer(palette = "Set3") +
  labs(title = "Top 5 Sectors in Current S&P 500") +
  theme_void() +
  geom_text(angle = 45, aes(label = company_count), position = position_stack(vjust = 0.5), size = 3, check_overlap = TRUE)

```




From this bar chart, we can observe that the largest sectors in the S&P 500 are Financials, Industrials, Information Technology, and
Health Care.


##### Average Daily Adjusted Close Price and Return

The Left Panel shows the mean adjusted close price across all companies from 2023 to 2024.

The Right Panel shows the average daily returns (%) across all companies from 2023 to 2024.


```{r}

plot_list <- list()

# Loop to calculate the mean of 'adjusted' and 'return' across all companies over time
for (metric in c("adjusted", "return")) {

  # Create the mean calculation for the chosen metric
  p <- returns_all %>%
    # Pivot the data so each symbol's 'metric' becomes a column
    pivot_wider(id_cols = date, names_from = symbol, values_from = all_of(metric)) %>%
    # Calculate the row-wise mean for all companies, excluding the date column
    mutate(mean_all = rowMeans(select(., -date), na.rm = TRUE)) %>%
    as.data.frame() %>%
    ggplot(aes(x = date, y = mean_all)) +
    geom_line(color = "blue") +
    labs(
      x = "", y = paste("", metric)) +
    theme_light()

  plot_list[[metric]] <- p
}

# Combine the two plots using grid.arrange
grid.arrange(
  plot_list[["adjusted"]],
  plot_list[["return"]],
  ncol = 2,
  top = textGrob(
    "Average Daily Adjusted Close Price (left) and Return (right) Across All Companies (2023â€“2024)",
    gp = gpar(fontsize = 11, fontface = "bold")
  )
)
```

###### Percentage Returns vs. Absolute Price Changes:
- Returns measure the relative change in stock prices from one period to the next.
- It displays a pronounced upward trend.While it seem somehow counter-intuitive at first, it is in fact the case in a growing economy or during periods of market expansion or high inflation. Furthermore, since the S&P 500 is composed of large, established companies, many of which have demonstrated long-term growth, the mean adjusted price naturally rises over time.

- While individual daily returns fluctuate considerably, their overall range tends to be constrained (usually between -3% and 3%, depending on market conditions).
- By contrast, adjusted stock prices reflect absolute changes, which can be substantial over time. As seen in the left panel of the chart, the adjusted price rises from approximately 165 to over 220 between 2023 and 2024â€”a significant increase.

######  Takeaways
- Both Price metrics and percentage returns are associated with the market but behave differently.
- Even though returns exhibit high volatility on a daily basis, the overall difference in cumulative percentage returns from the beginning to the end of the period is relatively stable when compared to absolute price changes.
- Stock prices tend to drift upwards or downwards more prominently in terms of the values.
- While the overall market grows, day-to-day price changes can be erratic. In other words, despite short-term fluctuations, the market's overall trajectory is positive.

- *In relation to the following analysis*, the percentage returns naturally normalize the data and seem more suitable for more meaningful comparisons across companies, regardless of their price levels. Thus, I did the clustering based on returns, hoping to identify companies with similar performance patterns.




##### Average daily stock returns across different sectors

"Average Daily Returns by Sector" shows the average daily stock returns across different sectors of companies. It tells us which sectors experienced higher or lower average daily returns.

Top Performing Sectors include Information Technology, Communication Services.
Sectors such as Financials and Real Estate fall in the middle range.
Sectors like Consumer Staples and Health Care have negative average daily returns.


```{r}
# Average daily stock returns across different sectors
mean_return <- returns_all %>%
  group_by(gics_sector) %>%
  summarise(mean_return = mean(return, na.rm = TRUE)) %>%
    arrange(desc(mean_return))

mean_return %>%
    ggplot(aes(x = reorder(gics_sector, mean_return), y = mean_return, fill = gics_sector)) +
    geom_bar(stat = "identity", fill = gray(0.8)) +
    coord_flip() +
    labs(title = "Average Daily Returns by Sector", x = "Sector", y = "Mean Return (%)") +
    theme_minimal() +
    theme(legend.position = "none")
```



Information Technology consistently has the highest average daily return, which aligns with broader market trends. Tech stocks have outperformed other sectors due to ongoing digital transformation and innovation.

At the same time, Information Technology and Financials display the most fluctuation in returns, indicating that risk is more concentrated in growth sectors. This suggests a trade-off between risk and return, especially when using competitive benchmarking.

It's important to note that the largest sectors in the S&P 500 are Financials, Industrials, Information Technology, and Health Care. Information Technology is both the most profitable and the most dominant sector. However, having the largest representation in the index doesnâ€™t necessarily equate to profitability, as seen with Health Care. This sector, which leans towards more public service-oriented industries, tends to be less volatile, offering steady but lower returns.

Interestingly, Financials was expected to be more profitable or have a higher return. However, it may be underperformed due to economic inflation, recent trade issues, and other macroeconomic factors affecting the financial industry.


## Bi-variate Analysis

To identify patterns in stock returns across companies, I applied **k-means clustering** to group companies based on their **return behavior**. The goal of this analysis was to group companies with similar return patterns, helping to reveal underlying structures in the data that may not be immediately apparent through traditional analysis.

##### Multidimensional Scaling (MDS) & Clustering






```{r}
# one - abs(correlation) to get dissimilarity
ret_matrix <- as.matrix(returns_wide[, -1]) %>% na.omit()
corr_matrix <- cor(as.matrix(returns_wide[, -1]), use = "complete.obs")
dissimilarity_matrix <- as.dist(1 - corr_matrix)


hc <- dissimilarity_matrix  %>% hclust() #hierarchical clustering
cluster <- cutree(hc, k = 5)
# plot dendrogram with cluster
hc %>%
        as.dendrogram() %>%
        color_branches(k = 10) %>%
        color_labels(k = 10) %>%
        set('labels_cex', 0.6) %>%
        plot(main = "Hiearchical Clustering")

# umap for 2D visualization

umap_results <- umap::umap(ret_matrixret_matrix, n_neighbors = 5, min_dist = 0.1, metric = "euclidean")
# visualize the results
umap_results %>%
  as.data.frame() %>%
  ggplot(aes(x = V1, y = V2)) +
  geom_point() +
  labs(title = "UMAP Visualization of Stock Returns", x = "UMAP 1", y = "UMAP 2") +
  theme_minimal()

```


```{r}
number_clusters <- 5 #how many clusters do you want to select

#use the ggdend function to make the chart workable in ggplot
hc %>%
  as.dendrogram() %>%
  color_branches(k = number_clusters) %>%
    color_labels(k = number_clusters) %>%
    set('labels_cex', 0.6) %>%
    as.ggdend() %>%
    ggplot() +
    theme_void() +
    theme(axis.text.x = element_blank(), axis.text.y = element_blank(), axis.title = element_blank())

```


```{r}
fviz_nbclust(dissimilarity_matrix, k.max = 8, FUNcluster = hcut, method = "wss")

fviz_nbclust(dissimilarity_matrix, k.max = 8, FUNcluster = hcut , method = "silhouette")
```



```{r}
#   k-means clustering with 5 centers
k5 <- kmeans(ret_matrix, centers = 5, nstart = 20)

# Perform PCA for visualization
pca_results <- prcomp(ret_matrix, scale. = TRUE)
pca_data <- as.data.frame(pca_results$x)

# Add cluster information
pca_data$cluster <- as.factor(k5$cluster)

# Plot PCA results with clusters
ggplot(pca_data, aes(x = PC1, y = PC2, color = cluster)) +
  geom_point(size = 2) +
  labs(title = "K-means Clustering (PCA Projection)", x = "PC1", y = "PC2") +
  theme_minimal()

fviz_cluster(k5, data = ret_matrix, geom = "point", stand = FALSE, ellipse.type = "convex", ellipse = TRUE, pointsize = 1.5) +
        labs(title = "K-means Clustering of Stock Returns", x = "PC1", y = "PC2") +
        theme_minimal()
# inspect cluster centers and find insights
k5$centers


```





## Possible Extensions



## Conclusion



