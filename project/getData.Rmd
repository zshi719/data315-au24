---
editor_options:
  markdown:
    wrap: 72
  echo: false
output:
  html_document:
    df_print: paged
  pdf_document: default
  
---


```{r,include=FALSE}
library(ggmap)
library(dplyr)
setwd("~/GithubProject/data315-au24/project")
register_google(key = "AIzaSyD3wR5ZmNZmv36w-LbmWixO5JKYmdWRtoI")
```

```{r}
knitr::opts_chunk$set(digits.signif = 4, tidy = TRUE, tidy.opts=list(blank = FALSE, warning = FALSE), message = TRUE, echo = TRUE,eval=FALSE, width='80%', widt.cutoff = '80')
```

# S&P 500 Top 50 Components by Market Cap


```{r,include=FALSE}
library(janitor)
library(gridExtra)
library(grid)
library(broom)
library(cluster)
library(tidyverse)

library(plotly)
library(ggplot2)

library(factoextra)
library(xts)
library(TTR)
library(quantmod)
library(dplyr)
library(yfR)
library(rvest)
library(knitr)
library(tidyquant)
library(purrr)
library(writexl)
library(tidyr)
library(knitr)
library(dplyr)
library(timeR)
conflicted::conflict_prefer("mutate", "dplyr")
conflicted::conflict_prefer("filter", "dplyr")
conflicted::conflict_prefer("lag", "dplyr")
library(rcartocolor)
nColor <- 12
ticker_colors <- carto_pal(12, "Safe")
ticker_colors <- c("#88CCEE", "#CC6677", "#DDCC77" ,"#117733", "#332288" ,"#AA4499","#999933" ,"#44AA99", "#882255", "#6699CC", "#888888")


top50_symbol = c("AAPL", "NVDA", "MSFT", "AMZN", "META", "GOOGL", "BRK-B","AVGO", 
             "GOOG", "LLY", "JPM", "TSLA", "XOM", "UNH", "V", "MA", "HD", "PG", 
             "COST", "JNJ", "WMT", "NFLX", "ABBV", "CRM", "BAC", "ORCL", "MRK", 
             "KO", "CVX", "AMD", "PEP", "ACN", "LIN", "CSCO", "TMO", "MCD", 
             "ADBE", "WFC", "IBM", "GE", "ABT", "CAT", "NOW", "QCOM", "PM", 
             "ISRG", "VZ", "TXN", "DIS", "DHR")

```

```{r, eval=FALSE}
pull_stock_data <- function(symbol) {
  stock_data <- tryCatch({
    tq_get(top50_symbol, from = "2022-12-31") %>%
      as.data.frame() %>% 
      mutate(daily_return = (adjusted / lag(adjusted) - 1) * 100) %>% na.omit()
  }, error = function(e) {
    return(NULL)
  })
  
  
  return(stock_data)
}
```

```{r, eval=FALSE,warning=FALSE}
timer <- createTimer(precision = "ms") 
timer$start("e")

data <- pull_stock_data(top50_symbol)

timer$stop("e")

stock_data_list <- split(data, data$symbol)


write_xlsx(stock_data_list, "stock_data_by_company.xlsx")

```



```{r}
current <- read.csv("data/company_data_full.csv")
get_lat_long <- function(address) {
  result <- geocode(address, output = "latlona", source = "google")
  return(result)
}

current <- current %>%
  mutate(full_address = paste(headquarters_location, "USA", sep = ", "))

current <- current %>%
  rowwise() %>%
  mutate(geo_data = list(get_lat_long(full_address))) %>%
  mutate(latitude = geo_data$lat, longitude = geo_data$lon) %>%
  select(-geo_data)

# Print the updated dataset with latitude and longitude
print(head(current))
```


## fetch CITY geocodes
```{r,}

get_lat_long <- function(address) {
  result <- geocode(address, output = "latlona", source = "google")
  return(result)
}

# Add a full address column to the 'current' data for geocoding
current <- current %>%
  mutate(full_address = paste(headquarters_location, "USA", sep = ", "))

# Fetch latitude and longitude for each company's headquarters
current <- current %>%
  rowwise() %>%
  mutate(geo_data = list(get_lat_long(full_address))) %>%
  mutate(latitude = geo_data$lat, longitude = geo_data$lon) %>%
  select(-geo_data)

write_xlsx(current, "current_new.xlsx")
write_csv(current, "data/current_new.csv")
```

## fetch headquarters HQ geocodes

```{r}
data <- read.csv("data/current_new.csv")


get_hq_geocoding <- function(company_name, headquarters) {
  # Combine company name and headquarters location for query
  query <- paste(company_name, headquarters, sep = ", ")
  tryCatch({
    # Fetch geocode data
    result <- geocode(query, output = "latlona", source = "google")
    return(data.frame(hq_lat = result$lat, hq_long = result$lon))
  }, error = function(e) {
    warning(paste("Failed to geocode:", query))
    return(data.frame(hq_lat = NA, hq_long = NA))  # Return NA for failed geocoding
  })
}


data <- read.csv("data/current_new.csv", stringsAsFactors = FALSE)


error_log <- data.frame(company_name = character(), headquarters = character(), error_message = character())

# Apply geocoding function to each row
data <- data %>%
  rowwise() %>%
  mutate(
    hq_result = list(get_hq_geocoding(security, headquarters_location)),
    hq_lat = hq_result$hq_lat,
    hq_long = hq_result$hq_long
  ) %>%
  select(-hq_result)

# Log errors (rows with NA for hq_lat or hq_long)
error_log <- data %>%
  filter(is.na(hq_lat) | is.na(hq_long)) %>%
  select(security, headquarters_location) %>%
  mutate(error_message = "Failed to fetch HQ coordinates")

# Save error log for review
write.csv(error_log, "data/error_log.csv", row.names = FALSE)

# Save the updated dataset with HQ coordinates
write.csv(data, "data/current_new_with_hq_coords.csv", row.names = FALSE)
```

```{r,}

get_hq_geocoding2 <- function(company_name, headquarters) {
  # Combine company name and headquarters location for query
  query <- paste(company_name, headquarters, sep = ", ")
  tryCatch({
    # Fetch geocode data
    result <- geocode(query, output = "latlona", source = "google")
    return(data.frame(hq_lat = result$lat, hq_long = result$lon, query = query))
  }, error = function(e) {
    warning(paste("Failed to geocode:", query))
    return(data.frame(hq_lat = NA, hq_long = NA, query = query))  # Return NA for failed geocoding
  })
}


data <- read.csv("data/current_new.csv", stringsAsFactors = FALSE)


error_log <- data.frame(company_name = character(), headquarters = character(), error_message = character())


data <- data %>%
  rowwise() %>%
  mutate(
    geocode_result = list(get_hq_geocoding2(security, headquarters_location)),
    hq_lat = geocode_result$hq_lat,
    hq_long = geocode_result$hq_long,
    query = geocode_result$query
  ) %>%
  ungroup() %>%
  select(-geocode_result)  # Remove intermediate results

# Log errors (rows with NA for hq_lat or hq_long)
error_log <- data %>%
  filter(is.na(hq_lat) | is.na(hq_long)) %>%
  select(security, headquarters_location, query) %>%
  mutate(error_message = "Failed to fetch HQ coordinates")


write.csv(error_log, "data/error_log.csv", row.names = FALSE)
write.csv(data, "data/current_new_with_hq_coords.csv", row.names = FALSE)

```

```{r,}
get_hq_geocoding <- function(company_name, headquarters) {
  # Combine company name and headquarters location
  query <- paste(company_name, headquarters, "USA", sep = ", ")
  tryCatch({
    # Fetch geocode data
    result <- geocode(query, output = "latlona", source = "google")
    if (is.na(result$lat) | is.na(result$lon)) {
      stop("Geocoding failed or returned ambiguous result")
    }
    return(data.frame(hq_lat = result$lat, hq_long = result$lon, query = query))
  }, error = function(e) {
    warning(paste("Failed to geocode:", query))
    return(data.frame(hq_lat = NA, hq_long = NA, query = query))  # Return NA for failed geocoding
  })
}

data <- read.csv("data/current_new.csv", stringsAsFactors = FALSE)


data <- data %>%
  rowwise() %>%
  mutate(
    geocode_result = list(get_hq_geocoding(security, headquarters_location)),
    hq_lat = geocode_result$hq_lat,
    hq_long = geocode_result$hq_long,
    query = geocode_result$query
  ) %>%
  ungroup() %>%
  select(-geocode_result)  # Remove intermediate results

# Log errors (rows with NA for hq_lat or hq_long)
error_log <- data %>%
  filter(is.na(hq_lat) | is.na(hq_long)) %>%
  select(security, headquarters_location, query) %>%
  mutate(error_message = "Failed to fetch HQ coordinates")

# Save error log for manual review
write.csv(error_log, "data/error_log.csv", row.names = FALSE)

# Save the updated dataset with HQ coordinates
write.csv(data, "data/current_new_with_hq_coords.csv", row.names = FALSE)
```



```{r, warning=FALSE}
setwd("~/GithubProject/data315-au24/project")
library(dplyr)
library(lubridate)
library(skimr)
library(dplyr)
library(lubridate)
library(skimr)
library(ggplot2)
library(tidyquant)
library(rcartocolor)
pal <- carto_pal(12, "Pastel")
```


```{r, warning=FALSE}
sp500_data <- read.csv("data/sp500_company_latest.csv") %>% janitor::clean_names() %>% 
  mutate(date_added = as.Date(date_added)) %>%
  mutate(founded = as.Date(founded))
head(sp500_data)
```


```{r, warning=FALSE}
# print column names
colnames(sp500_data)
```


```{r, echo=TRUE, warning=FALSE}


sp500_grouped <- sp500_data %>%
   arrange(date_added) %>%
  mutate(year_added = year(date_added)) %>%
  group_by(year_added) %>%
  summarize(
    companies = list(symbol),
    details = list(data.frame(security, sector, sub_industry, headquarters_location))
  )

# plot the number of companies added to the S&P 500 each year
sp500_grouped %>%
  ggplot(aes(x = year_added, y = lengths(companies))) +
  geom_bar(stat = "identity", fill = carto_pal(12, "Safe")[1]) +
  labs(
    title = "Number of Companies Added to the S&P 500 Each Year",
    x = "Year",
    y = "Number of Companies"
  ) +
  theme_tq()
```


```{r}
# 每个行业选择故股票份额前10
# Select the top N companies by market cap weight in each sector
top_companies <- sp500_data %>%
  group_by(sector) %>%
  slice_max(order_by = market_cap_weight, n = 10) %>%  # Change n for more/less companies
  ungroup()

top_companies %>%
  ggplot(aes(x = date_added, y = reorder(symbol, date_added))) +
  geom_point(aes(color = sector), size = 2, position = position_jitter(width = 0.4, height = 0.2)) +
  geom_text(aes(label = symbol), vjust = -0.5, size = 2) +
  scale_color_manual(values = pal) +
  labs(
    title = "Demo: Timeline of Selected Companies by Date_added",
    x = "Date Added",
    y = "Ticker Symbol",
    color = "Sector"
  ) +
  theme_minimal() +
  theme(
    # blank for y
    axis.text.y = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom"
  )

```

```{r}
# Filter top companies to label
top_companies <- sp500_data %>%
  group_by(sector) %>%
  slice_max(order_by = market_cap_weight, n = 2) %>%  # Select top 3 by sector
  ungroup()

# Plot all companies as dots and label only selected ones
sp500_data %>%
  ggplot(aes(x = date_added, y = reorder(symbol, date_added))) +
  # All companies as dots
  geom_point(aes(color = sector), size = 2, alpha = 0.5) +
  # Add labels for selected companies
  geom_text(data = top_companies,
            aes(label = symbol),
            vjust = -1,
            size = 2,
            color = "black") +
  scale_color_manual(values = pal) +
  labs(
    title = "Demo: Timeline of ALL Current S&P 5000 Companies with Selected Labels",
    x = "Date Added",
    y = "Ticker Symbol",
    color = "Sector",
    caption ="can turn this into an animation whereas users click on the dot and it will show the company details"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 0, hjust = 1),
    axis.text.y = element_blank(),
    legend.position = "bottom",
    plot.title = element_text(size = 12, color = "blue"),
    plot.margin = margin(10, 0, 0, 10),
    # magenta for caption; and caption large font
    plot.caption = element_text(color = "magenta", size = 12)
  )


```
# History Problem
```{r}
library(dplyr)

# Load the cleaned dataset with lat-long
change_history <- read.csv("data/sp500_change_history.csv", stringsAsFactors = FALSE)
head(change_history)
geolocation_data <- read.csv("data/sp500_company_latest.csv", stringsAsFactors = FALSE)
```
```{r}
# Load data
library(dplyr)
change_history <- read.csv("data/sp500_change_history.csv", stringsAsFactors = FALSE)

# Convert date column to Date type
change_history$date <- as.Date(change_history$date)

# Extract changes for the target year (e.g., 2024)
change_2024 <- change_history %>%
  filter(format(date, "%Y") == "2024") %>%
  arrange(date)

# Ensure 'added_ticker' and 'removed_ticker' match 'symbol' in geolocation data
change_history <- change_history %>%
  left_join(geolocation_data, by = c("added_ticker" = "symbol")) %>%
  rename(
    added_hq_long = hq_long,
    added_hq_lat = hq_lat
  ) %>%
  left_join(geolocation_data, by = c("removed_ticker" = "symbol")) %>%
  rename(
    removed_hq_long = hq_long,
    removed_hq_lat = hq_lat
  )

# Added companies
added_companies <- change_history %>%
  filter(!is.na(added_ticker)) %>%
  select(date, added_ticker, added_hq_long, added_hq_lat)

# Removed companies
removed_companies <- change_history %>%
  filter(!is.na(removed_ticker)) %>%
  select(date, removed_ticker, removed_hq_long, removed_hq_lat)


```


```{r}
# Combine added and removed companies
change_combined <- change_history %>%
  mutate(
    hq_long = ifelse(!is.na(added_ticker), geolocation_data$hq_long[match(added_ticker, geolocation_data$symbol)], 
                     geolocation_data$hq_long[match(removed_ticker, geolocation_data$symbol)]),
    hq_lat = ifelse(!is.na(added_ticker), geolocation_data$hq_lat[match(added_ticker, geolocation_data$symbol)], 
                    geolocation_data$hq_lat[match(removed_ticker, geolocation_data$symbol)]),
    change_type = ifelse(!is.na(added_ticker), "Added", "Removed")
  )

# Check for missing data
change_combined <- change_combined %>% filter(!is.na(hq_long) & !is.na(hq_lat))

ggplot(change_combined, aes(x = hq_long, y = hq_lat, color = change_type)) +
  geom_point(size = 3) +
  labs(
    title = "S&P 500 Company Changes: Added and Removed",
    subtitle = "Geographic distribution of changes",
    x = "Longitude",
    y = "Latitude",
    color = "Change Type"
  ) +
  theme_tq()

```


```{r}

# Add year and month columns for animation
change_combined <- change_combined %>%
  mutate(
    year_month = format(as.Date(date), "%Y-%m")
  )
animated_plot <- ggplot(change_combined, aes(x = hq_long, y = hq_lat, color = change_type)) +
  geom_point(size = 3) +
  labs(
    title = "S&P 500 Company Changes Over Time: Added and Removed",
    subtitle = "Time: {closest_state}",
    x = "Longitude",
    y = "Latitude",
    color = "Change Type"
  ) +
  theme_minimal() +
  transition_states(year_month, transition_length = 1, state_length = 1) +
  ease_aes('linear')
```
